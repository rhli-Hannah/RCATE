data.gbm <- data.frame(cbind(y.tr[sample.id], x[sample.id,]))
colnames(data.gbm) <- c("y.tr", paste0("X", 1:ncol(x)))
model <- gbm::gbm(y.tr ~ ., data = data.gbm, distribution = "laplace",
weights = w.tr[sample.id], n.trees = object$n.trees.gbm,
interaction.depth = 2)
df.x <- data.frame(x.cond)
pred.gbm[i,] <- gbm::predict.gbm(model, df.x, n.trees = object$n.trees.gbm)
}
ci <- apply(pred.gbm, 2, function(x) quantile(x,probs = c(0.025,0.975)))
plot(x.select,pred,type = 'l',ylim = c(-15,15))
lines(x.select,ci[1,],ylim = c(-15,15), col='red')
lines(x.select,ci[2,],ylim = c(-15,15), col='red')
sample.id
data.gbm <- data.frame(cbind(y.tr[sample.id], x[sample.id,]))
View(data.gbm)
colnames(data.gbm) <- c("y.tr", paste0("X", 1:ncol(x)))
model <- gbm::gbm(y.tr ~ ., data = data.gbm, distribution = "laplace",
weights = w.tr[sample.id], n.trees = object$n.trees.gbm,
interaction.depth = 2)
df.x <- data.frame(x.cond)
gbm::predict.gbm(model, df.x, n.trees = object$n.trees.gbm)
pred <- predict(model,data.frame(x.cond))
fit <- rcate.ml(X,y,d,method='DR',algorithm='NN',dropout.nn=c(0),n.cells.nn=c(3,3))
object=fit
model <- object$model
algorithm <- object$algorithm
y.tr <- object$y.tr
w.tr <- object$w.tr
x <- object$x
x.colmean <- colMeans(object$x)
x.cond <- matrix(rep(colMeans(object$x), times=200),
nrow = 200,ncol = ncol(object$x), byrow=TRUE)
x.cond[,variable.col] <- seq(min(object$x[,variable.col]),max(object$x[,variable.col]),length.out = 200)
x.select <- seq(min(object$x[,variable.col]),max(object$x[,variable.col]),length.out = 200)
pred <- rowMeans(predict(model,data.frame(x.cond)))
predict(model,data.frame(x.cond))
pred <- rowMeans(predict(model,x.cond))
plot(pred)
predict(model,x.cond)
#' @return a list of components
#' \itemize{
#'  \item predict - a robust estimation result of CATE.
#'  \item x - matrix of predictors.
#'  \item algorithm - fitting algorithm.
#'  \item model - "rcate.ml" object.
#'  \item method - estimation method.
#'  }
#' @rdname predict.rcate.ml
#' @export
predict.rcate.ml <- function(object, x, ...) {
algorithm <- object$algorithm
model <- object$model
if (algorithm == "GBM") {
predict <- predict(model, data.frame(x), n.trees = object$n.trees.gbm)
} else if (algorithm == "NN") {
predict <- rowMeans(predict(model,x))
model <- NULL
}
return(list(predict = predict, x = x, algorithm = object$algorithm,
model = model, method = object$method))
}
y_pred <- predict(fit,x_val)$predict
plot(tau_val,y_pred);abline(0,1)
pred <- rowMeans(predict(model,x.cond))
pred.nn <- matrix(NA,nrow = 100, ncol = 200)
sample.id <- sample(1:1000,1000,replace = TRUE)
data.gbm <- data.frame(cbind(y.tr[sample.id], x[sample.id,]))
x = as.matrix(x[sample.id,])
y = as.matrix(y.tr[sample.id])
keras::compile(model, loss = "mae", optimizer = "adam")
history <- keras::fit(model,x, y, epochs = 100, verbose = 0, sample_weight = w.tr[sample.id])
fitted.values <- rowMeans(predict(model,x))
fitted.values <- rowMeans(predict(model,x.cond))
plot(fitted.values)
pred.nn <- matrix(NA,nrow = 100, ncol = 200)
for (i in 1:100) {
sample.id <- sample(1:1000,1000,replace = TRUE)
x = as.matrix(x[sample.id,])
y = as.matrix(y.tr[sample.id])
keras::compile(model, loss = "mae", optimizer = "adam")
history <- keras::fit(model,x, y, epochs = 100, verbose = 0, sample_weight = w.tr[sample.id])
pred.nn[i,] <- rowMeans(predict(model,x.cond))
}
View(pred.nn)
#' Marginal treatment effect plot from machine learning algorithms.
#'
#' \code{marginal.rcate.ml} Returns the variable importance level from "rcate.ml" model.
#'
#' @param object "rcate.ml" object.
#' @param variable.col the column number of interested variable. Default is 1.
#' @param ... other.
#' @rdname marginal.rcate.ml
#' @export
marginal.rcate.ml <- function(object, variable.col=1,...){
model <- object$model
algorithm <- object$algorithm
y.tr <- object$y.tr
w.tr <- object$w.tr
x <- object$x
x.colmean <- colMeans(object$x)
x.cond <- matrix(rep(colMeans(object$x), times=200),
nrow = 200,ncol = ncol(object$x), byrow=TRUE)
x.cond[,variable.col] <- seq(min(object$x[,variable.col]),max(object$x[,variable.col]),length.out = 200)
x.select <- seq(min(object$x[,variable.col]),max(object$x[,variable.col]),length.out = 200)
if (algorithm =='GBM') {
pred <- predict(model,data.frame(x.cond))
plot(x.select,pred,type = 'l',ylim = c(-15,15))
} else if (algorithm == 'NN') {
pred <- rowMeans(predict(model,x.cond))
plot(x.select,pred,type = 'l',ylim = c(-15,15))
}
}
marginal.rcate.ml(fit,1)
#' Marginal treatment effect plot from machine learning algorithms.
#'
#' \code{marginal.rcate.ml} Returns the variable importance level from "rcate.ml" model.
#'
#' @param object "rcate.ml" object.
#' @param variable.col the column number of interested variable. Default is 1.
#' @param ... other.
#' @rdname marginal.rcate.ml
#' @export
marginal.rcate.ml <- function(object, variable.col=1,...){
model <- object$model
algorithm <- object$algorithm
y.tr <- object$y.tr
w.tr <- object$w.tr
x <- object$x
x.colmean <- colMeans(object$x)
x.cond <- matrix(rep(colMeans(object$x), times=200),
nrow = 200,ncol = ncol(object$x), byrow=TRUE)
x.cond[,variable.col] <- seq(min(object$x[,variable.col]),max(object$x[,variable.col]),length.out = 200)
x.select <- seq(min(object$x[,variable.col]),max(object$x[,variable.col]),length.out = 200)
if (algorithm =='GBM') {
pred <- predict(model,data.frame(x.cond))
plot(x.select,pred,type = 'l')
} else if (algorithm == 'NN') {
pred <- rowMeans(predict(model,x.cond))
plot(x.select,pred,type = 'l')
}
}
fit <- rcate.ml(X,y,d,method='RL',algorithm='GBM')
marginal.rcate.ml(fit,1)
#' Marginal treatment effect plot from machine learning algorithms.
#'
#' \code{marginal.rcate.ml} Returns the variable importance level from "rcate.ml" model.
#'
#' @param object "rcate.ml" object.
#' @param variable.col the column number of interested variable. Default is 1.
#' @param ... other.
#' @rdname marginal.rcate.ml
#' @export
marginal.rcate.ml <- function(object, variable.col=1,...){
model <- object$model
algorithm <- object$algorithm
x <- object$x
x.colmean <- colMeans(object$x)
x.cond <- matrix(rep(colMeans(object$x), times=200),
nrow = 200,ncol = ncol(object$x), byrow=TRUE)
x.cond[,variable.col] <- seq(min(object$x[,variable.col]),max(object$x[,variable.col]),length.out = 200)
x.select <- seq(min(object$x[,variable.col]),max(object$x[,variable.col]),length.out = 200)
if (algorithm =='GBM') {
pred <- predict(model,data.frame(x.cond))
plot(x.select,pred,type = 'l')
} else if (algorithm == 'NN') {
pred <- rowMeans(predict(model,x.cond))
plot(x.select,pred,type = 'l')
}
}
marginal.rcate.ml(fit,1)
marginal.rcate.ml(fit,1)
marginal.rcate.ml(fit,1)
marginal.rcate.ml(fit,1)
n <- 1000; p <- 3; set.seed(2223)
X <- matrix(rnorm(n*p,0,1),nrow=n,ncol=p)
tau = 6*sin(2*X[,1])+3*(X[,2]+3)*X[,3]
p = 1/(1+exp(-X[,1]+X[,2]))
d = rbinom(n,1,p)
t = 2*d-1
y = 100+4*X[,1]+X[,2]-3*X[,3]+tau*t/2 + rnorm(n,0,1); set.seed(2223)
x_val = matrix(rnorm(200*3,0,1),nrow=200,ncol=3)
tau_val = 6*sin(2*x_val[,1])+3*(x_val[,2]+3)*x_val[,3]
# Use R-learning method and GBM to estimate CATE
fit <- rcate.ml(X,y,d,method='RL',algorithm='GBM')
#' Marginal treatment effect plot from machine learning algorithms.
#'
#' \code{marginal.rcate.ml} Returns the variable importance level from "rcate.ml" model.
#'
#' @param object "rcate.ml" object.
#' @param variable.col the column number of interested variable. Default is 1.
#' @param ... other.
#' @rdname marginal.rcate.ml
#' @export
marginal.rcate.ml <- function(object, variable.col=1,...){
model <- object$model
algorithm <- object$algorithm
x <- object$x
x.colmean <- colMeans(object$x)
x.cond <- matrix(rep(colMeans(object$x), times=200),
nrow = 200,ncol = ncol(object$x), byrow=TRUE)
x.cond[,variable.col] <- seq(min(object$x[,variable.col]),max(object$x[,variable.col]),length.out = 200)
x.select <- seq(min(object$x[,variable.col]),max(object$x[,variable.col]),length.out = 200)
if (algorithm =='GBM') {
pred <- predict(model,data.frame(x.cond))
plot(x.select,pred,type = 'l')
} else if (algorithm == 'NN') {
pred <- rowMeans(predict(model,x.cond))
plot(x.select,pred,type = 'l')
}
}
marginal.rcate.ml(fit,1)
marginal.rcate.ml(fit,2)
marginal.rcate.ml(fit,3)
Btilde.fun <- function(x, lambda2, knots2) {
B <- splines::bs(x, degree = 3, knots = knots2, Boundary.knots = c(-4, 4))
D <- diff(diag(ncol(B)), differences = 2)
Omega <- crossprod(D)
n <- length(x)
M <- 1/n * crossprod(B) + lambda2 * Omega
R <- chol(M)
R1 <- solve(R)
Btilde.mat <- B %*% R1
return(Btilde.mat)
}
B_R <- function(x2, x3, lambda2br, knots.op1,colnum) {
Btilde0 <- NULL
result <- knot(x3, knots.op1)
for (i in 1:length(colnum)) {
Btilde1 <- Btilde.fun(x2[, i], lambda2br, result[, i])
Btilde0 <- cbind(Btilde0, Btilde1)
}
return(Btilde0)
}
# Genrate knots
knot <- function(x, knots.op) {
knot.mat = apply(x, 2, function(y)
stats::quantile(y, probs = utils::head(seq(0, 1, length.out = as.numeric(knots.op + 2)), -1)[-1]))
return(knot.mat)
}
# Adaptive INIS
adaptINIS <- function(x, y, testdata = NULL, lambda.pen.list = NULL,
folds = NULL, quant = NULL, kfold = NULL, knots = NULL, eps0 = 1e-06,
DOISIS = TRUE, maxloop = 10, trace = FALSE, detailed = FALSE) {
t0 = proc.time()[1]
cat("starting adaptINIS, NIS algorithm, adatively choose number of variables\n")
n <- nrow(x)
p <- ncol(x)
# if(is.null(nsis)) nsis=min(floor(n/log(n)),p-1)
if (is.null(knots)) {
knots = ceiling(n^0.2)
}
if (is.null(folds)) {
temp = sample(1:n, n, replace = FALSE)
if (is.null(kfold))
kfold = 5
for (i in 1:kfold) {
folds[[i]] = setdiff(1:n, temp[seq(i, n, kfold)])
}
}
if (is.null(quant)) {
quant = 1
}
df0 <- knots + 1
xbs = matrix(0, n, df0 * p)
for (i in 1:p) {
xbs[, (i - 1) * (df0) + (1:df0)] = splines::ns(x[, i], df = df0)
}
tempresi <- rep(0, p)
curloop = 1
for (i in 1:p) {
tempfit <- stats::lm.fit(x = cbind(1, xbs[, (i - 1) * df0 + 1:df0]), y = y)
tempresi[i] <- sum(tempfit$residuals^2)
}
used.list <- tempresi
used.sort <- sort(used.list, method = "sh", index = TRUE, decreasing = FALSE)
initRANKorder <- used.sort$ix
mindex <- sample(1:n)
mresi = NULL
for (i in 1:p) {
tempfit <- stats::lm.fit(x = cbind(1, xbs[, (i - 1) * df0 + 1:df0]), y = y[mindex])
mresi[i] <- sum(tempfit$residuals^2)
}
resi.thres = stats::quantile(mresi, 1 - quant)
nsis <- max(min(sum(used.list < resi.thres), floor(n/df0/3)), 2)
SISind <- sort(initRANKorder[1:nsis])
if (!DOISIS)
return(list(initRANKorder = initRANKorder, SISind = SISind, nsis = nsis))
cat("loop ", curloop, "...SISind ", SISind, "\n")
pick.ind = initRANKorder[1:nsis]
return(pick.ind)
}
#' t = 2*d-1
#' y = 100+tau*t/2 + rnorm(n,0,1); set.seed(2223)
#' x_val = matrix(rnorm(200*2,0,1),nrow=200,ncol=2)
#' tau_val = 3*x_val[,1]-x_val[,2]
#'
#' fit <- rcate.am(X,y,d,lambda.smooth = 2, method = 'RL')
#' y_pred <- predict(fit,x_val)$pred
#' plot(tau_val,y_pred);abline(0,1)
#'
#' @export
rcate.am <- function(x, y, d, method = "MCMEA", NIS = TRUE, nknots = NA,
lambda.smooth = 1, nlambda = 30, nfolds = 5, n.trees.p = 40000,
shrinkage.p = 0.005, n.minobsinnode.p = 10,
interaction.depth.p = 1, cv.p = 2, n.trees.mu = c(1:50) * 50,
shrinkage.mu = 0.01,
n.minobsinnode.mu = 5, interaction.depth.mu = 5, cv.mu = 5) {
options(warn=-1)
# Calculate T=2D-1
t <- 2 * d - 1
if (is.vector(x)) {
x <- matrix(x, ncol = 1)
}
# Number of rows and columns of X
row <- nrow(x)
col <- ncol(x)
# Standardize X
mean.x <- apply(x, 2, mean)
sd.x <- apply(x, 2, sd)
center.x <- (x - mean.x)/sd.x
# Calculate number of knots
if (is.na(nknots)) {
nknots <- floor(sqrt(row)/2)
}
# NIS
if (col < floor(row/log(row)) | NIS == FALSE) {
colnum <- 1:col
} else {
colnum_d <- adaptINIS(x, d)
colnum_y1 <- adaptINIS(x[d == 1, ], y[d == 1])
colnum_y0 <- adaptINIS(x[d == 0, ], y[d == 0])
colnum <- sort(unique(union(union(colnum_d, colnum_y0), colnum_y1)))
}
group <- rep(1:length(colnum), each = nknots + 3)
x.tr <- center.x[, colnum]
# If X has only one dimension, transform it into a matrix with one column
if (is.vector(x.tr)) {
x.tr <- matrix(x.tr, ncol = 1)
}
# Estimate mu0(x), mu1(x) and p(x)
data.p <- data.frame(cbind(factor(d), x))
colnames(data.p) <- c("d", paste0("X", 1:ncol(x)))
data.p$d <- as.factor(data.p$d)
gbmGrid.p <- expand.grid(interaction.depth = interaction.depth.p,
n.trees = n.trees.p, shrinkage = shrinkage.p,
n.minobsinnode = n.minobsinnode.p)
gbmFit.p <- caret::train(d ~ ., data = data.p, method = "gbm",
verbose = FALSE, trControl = caret::trainControl(method = "cv", number = cv.p),
tuneGrid = gbmGrid.p)
pscore.hat <- caret::predict.train(gbmFit.p, newdata = data.p, type = "prob")[, 2]
data00 <- data.frame(cbind(y, x, d))
colnames(data00) <- c("y", paste0("X", 1:ncol(x)), "d")
# data020 <- data00[data00$d == 0, ]
# data021 <- data00[data00$d == 1, ]
gbmGrid.mu <- expand.grid(interaction.depth = interaction.depth.mu,
n.trees = n.trees.mu, shrinkage = shrinkage.mu,
n.minobsinnode = n.minobsinnode.mu)
gbmFit.mu <- caret::train(y ~ ., data = data00[, -ncol(data00)],
method = "gbm", verbose = FALSE, trControl = caret::trainControl(method = "cv",
number = cv.mu), tuneGrid = gbmGrid.mu, metric = "MAE")
# gbmFit.mu1 <- caret::train(y ~ ., data = data021[, -ncol(data021)],
#                            method = "gbm", verbose = FALSE, trControl = caret::trainControl(method = "cv",
#                            number = cv.mu), tuneGrid = gbmGrid.mu, metric = "MAE")
# gbmFit.mu0 <- caret::train(y ~ ., data = data020[, -ncol(data020)],
#                            method = "gbm", verbose = FALSE, trControl = caret::trainControl(method = "cv",
#                            number = cv.mu), tuneGrid = gbmGrid.mu, metric = "MAE")
#
# mu0 <- caret::predict.train(gbmFit.mu0, newdata = data00)
# mu1 <- caret::predict.train(gbmFit.mu1, newdata = data00)
mu.ea <- caret::predict.train(gbmFit.mu, newdata = data00)
# Do transformation
if (method == "MCMEA") {
w.tr <- 1/(t * pscore.hat + (1 - t)/2)
y.tr <- (y - mu.ea) * w.tr
wmat.tr <- matrix(0, row, row)
diag(wmat.tr) <- w.tr * t/2
Btilde <- B_R(x.tr, x.tr, lambda.smooth, nknots, colnum)
x.tr1 <- wmat.tr %*% cbind(rep(1, row), Btilde)
} else if (method == "RL") {
w.tr <- 1
y.tr <- (y - mu.ea) * w.tr
wmat.tr <- matrix(0, row, row)
diag(wmat.tr) <- w.tr * (t - 2 * pscore.hat + 1)/2
Btilde <- B_R(x.tr, x.tr, lambda.smooth, nknots, colnum)
x.tr1 <- wmat.tr %*% cbind(rep(1, row), Btilde)
}
# Fit the weighted LAD model with group SCAD
model <- rqPen::cv.rq.group.pen(x = x.tr1, y = y.tr, groups = as.factor(c(max(group)+1, group)),
tau = 0.5, intercept = FALSE, penalty = 'SCAD',
nfolds = nfolds, criteria = "BIC", nlambda = nlambda)
# Get coefficients and fitted value
coef <- coef(model)
fitted.values <- cbind(rep(1, nrow(Btilde)), Btilde) %*% coef
result <- list(model = model, method = method, algorithm = "SAM",
lambda.smooth = lambda.smooth, fitted.values = fitted.values,
x = x, y = y, d = d, mean.x = mean.x, sd.x = sd.x,
y.tr = y.tr, w.tr = w.tr,
coef = coef, colnum = colnum, nknots = nknots)
class(result) <- "rcate.am"
return(result)
}
n <- 1000; p <- 2; set.seed(2223)
X <- matrix(rnorm(n*p,0,1),nrow=n,ncol=p)
tau = 3*X[,1]-X[,2]
p = 1/(1+exp(-X[,1]+X[,2]))
d = rbinom(n,1,p)
t = 2*d-1
y = 100+tau*t/2 + rnorm(n,0,1); set.seed(2223)
x_val = matrix(rnorm(200*2,0,1),nrow=200,ncol=2)
tau_val = 3*x_val[,1]-x_val[,2]
fit <- rcate.am(X,y,d,lambda.smooth = 2, method = 'RL')
object=fit
algorithm <- object$algorithm
model <- object$model
colnum <- object$colnum
x <- object$x
x.colmean <- colMeans(object$x)
x.cond <- matrix(rep(colMeans(object$x), times=200),
nrow = 200,ncol = ncol(object$x), byrow=TRUE)
x.cond[,variable.col] <- seq(min(object$x[,variable.col]),max(object$x[,variable.col]),length.out = 200)
x.select <- seq(min(object$x[,variable.col]),max(object$x[,variable.col]),length.out = 200)
center.x <- apply(x, 2, function(x) (x - object$mean.x)/object$sd.x)
center.xval <- apply(x.cond, 2, function(x) (x - object$mean.x)/object$sd.x)
center.xval <- center.xval[, colnum]
center.x <- center.x[, colnum]
if (is.vector(center.xval) & is.vector(center.x)) {
center.xval <- matrix(center.xval, ncol = 1)
center.x <- matrix(center.x, ncol = 1)
}
Btilde.val <- B_R(center.xval, center.x, object$lambda.smooth, object$nknots, colnum)
predict <- cbind(rep(1, nrow(Btilde.val)), Btilde.val) %*% object$coef
plot(x.select,predict,type = 'l')
#' Marginal treatment effect plot from additive model.
#'
#' \code{marginal.rcate.am} Returns the variable importance level from "rcate.am" model.
#'
#' @param object "rcate.am" object.
#' @param variable.col the column number of interested variable. Default is 1.
#' @param ... other.
#' @rdname marginal.rcate.am
#' @export
marginal.rcate.am <- function(object, variable.col=1,...){
algorithm <- object$algorithm
model <- object$model
colnum <- object$colnum
x <- object$x
x.colmean <- colMeans(object$x)
x.cond <- matrix(rep(colMeans(object$x), times=200),
nrow = 200,ncol = ncol(object$x), byrow=TRUE)
x.cond[,variable.col] <- seq(min(object$x[,variable.col]),max(object$x[,variable.col]),length.out = 200)
x.select <- seq(min(object$x[,variable.col]),max(object$x[,variable.col]),length.out = 200)
center.x <- apply(x, 2, function(x) (x - object$mean.x)/object$sd.x)
center.xval <- apply(x.cond, 2, function(x) (x - object$mean.x)/object$sd.x)
if (algorithm == "SAM") {
center.xval <- center.xval[, colnum]
center.x <- center.x[, colnum]
if (is.vector(center.xval) & is.vector(center.x)) {
center.xval <- matrix(center.xval, ncol = 1)
center.x <- matrix(center.x, ncol = 1)
}
Btilde.val <- B_R(center.xval, center.x, object$lambda.smooth, object$nknots, colnum)
predict <- cbind(rep(1, nrow(Btilde.val)), Btilde.val) %*% object$coef
}
plot(x.select,predict,type = 'l')
}
n <- 1000; p <- 2; set.seed(2223)
X <- matrix(runif(n*p,-3,3),nrow=n,ncol=p)
tau = 3*X[,1]-X[,2]
p = 1/(1+exp(-X[,1]+X[,2]))
d = rbinom(n,1,p)
t = 2*d-1
y = 100+tau*t/2 + rnorm(n,0,1); set.seed(2223)
x_val = matrix(rnorm(200*2,0,1),nrow=200,ncol=2)
tau_val = 3*x_val[,1]-x_val[,2]
fit <- rcate.am(X,y,d,lambda.smooth = 2, method = 'RL')
y_pred <- predict(fit,x_val)$pred
plot(tau_val,y_pred);abline(0,1)
#' Marginal treatment effect plot from additive model.
#'
#' \code{marginal.rcate.am} Returns the variable importance level from "rcate.am" model.
#'
#' @param object "rcate.am" object.
#' @param variable.col the column number of interested variable. Default is 1.
#' @param ... other.
#' @rdname marginal.rcate.am
#' @export
marginal.rcate.am <- function(object, variable.col=1,...){
algorithm <- object$algorithm
model <- object$model
colnum <- object$colnum
x <- object$x
x.colmean <- colMeans(object$x)
x.cond <- matrix(rep(colMeans(object$x), times=200),
nrow = 200,ncol = ncol(object$x), byrow=TRUE)
x.cond[,variable.col] <- seq(min(object$x[,variable.col]),max(object$x[,variable.col]),length.out = 200)
x.select <- seq(min(object$x[,variable.col]),max(object$x[,variable.col]),length.out = 200)
center.x <- apply(x, 2, function(x) (x - object$mean.x)/object$sd.x)
center.xval <- apply(x.cond, 2, function(x) (x - object$mean.x)/object$sd.x)
if (algorithm == "SAM") {
center.xval <- center.xval[, colnum]
center.x <- center.x[, colnum]
if (is.vector(center.xval) & is.vector(center.x)) {
center.xval <- matrix(center.xval, ncol = 1)
center.x <- matrix(center.x, ncol = 1)
}
Btilde.val <- B_R(center.xval, center.x, object$lambda.smooth, object$nknots, colnum)
predict <- cbind(rep(1, nrow(Btilde.val)), Btilde.val) %*% object$coef
}
plot(x.select,predict,type = 'l')
}
marginal.rcate.am(fit,1)
devtools::check()
